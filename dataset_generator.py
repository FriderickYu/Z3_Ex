# æ–‡ä»¶ï¼šdataset_generator.py
# è¯´æ˜ï¼šåŸºäºçœŸå®é€»è¾‘è§„åˆ™çš„LSATé£æ ¼æ•°æ®é›†ç”Ÿæˆå™¨ï¼ˆé›†æˆmatplotlibå¯è§†åŒ–ï¼‰

import json
import logging
import random
import os
from typing import List, Dict, Any, Optional
from pathlib import Path

from dag.dag_builder import build_reasoning_dag
from dag.validator import validate_logical_steps
from dag.visualizer import visualize_dag
from distractor.generator import DistractorGenerator
from api_key.llm_dispatcher import LLMDispatcher
from utils.consistency_validator import ConsistencyValidator
from utils.enhanced_prompt_builder import EnhancedPromptBuilder
from utils.variable_manager import EnhancedVariableExtractor


class DatasetGenerator:
    """
    æ”¹è¿›çš„æ•°æ®é›†ç”Ÿæˆå™¨ï¼šä¸¥æ ¼æ§åˆ¶å˜é‡æ•°é‡ï¼Œç¡®ä¿é«˜è´¨é‡çš„æ¨ç†é¢˜ç›®
    é›†æˆï¼šmatplotlib + networkx å¯è§†åŒ–ï¼Œæ— å¤–éƒ¨ä¾èµ–
    """

    def __init__(self, llm_dispatcher: LLMDispatcher, prompt_template_path: str,
                 max_variables: int = 8, min_variables: int = 4,
                 enable_visualization: bool = True, viz_output_dir: str = "output/dag_visualizations"):
        """
        åˆå§‹åŒ–æ•°æ®é›†ç”Ÿæˆå™¨

        :param llm_dispatcher: LLMè°ƒåº¦å™¨å®ä¾‹
        :param prompt_template_path: promptæ¨¡æ¿æ–‡ä»¶è·¯å¾„
        :param max_variables: æœ€å¤§å˜é‡æ•°é‡
        :param min_variables: æœ€å°å˜é‡æ•°é‡
        :param enable_visualization: æ˜¯å¦å¯ç”¨å¯è§†åŒ–
        :param viz_output_dir: å¯è§†åŒ–å›¾ç‰‡è¾“å‡ºç›®å½•
        """
        self.llm = llm_dispatcher
        self.logger = logging.getLogger("dataset_generator")

        # ä½¿ç”¨æ”¹è¿›çš„å˜é‡æå–å™¨ï¼ˆå¸¦æ•°é‡æ§åˆ¶ï¼‰
        self.extractor = EnhancedVariableExtractor(
            max_variables=max_variables,
            min_variables=min_variables
        )
        self.validator = ConsistencyValidator(strictness_level="medium")
        self.prompt_builder = EnhancedPromptBuilder(prompt_template_path)

        # è´¨é‡æ§åˆ¶å‚æ•°
        self.max_retry_attempts = 5
        self.min_valid_steps = 2
        self.max_valid_steps = 6

        # å˜é‡æ§åˆ¶å‚æ•°
        self.max_variables = max_variables
        self.min_variables = min_variables

        # å¯è§†åŒ–å‚æ•°
        self.enable_visualization = enable_visualization
        self.viz_output_dir = viz_output_dir

        # åˆ›å»ºå¯è§†åŒ–è¾“å‡ºç›®å½•
        if self.enable_visualization:
            Path(self.viz_output_dir).mkdir(parents=True, exist_ok=True)
            self.logger.info(f"âœ… å¯è§†åŒ–åŠŸèƒ½å·²å¯ç”¨ï¼Œè¾“å‡ºç›®å½•: {self.viz_output_dir}")

    def _generate_dag_visualization(self, root_node, sample_id: str, metadata: Dict = None) -> Optional[str]:
        """
        ä¸ºDAGç”Ÿæˆå¯è§†åŒ–å›¾ç‰‡

        :param root_node: DAGæ ¹èŠ‚ç‚¹
        :param sample_id: æ ·æœ¬å”¯ä¸€æ ‡è¯†
        :param metadata: æ ·æœ¬å…ƒæ•°æ®ï¼ˆç”¨äºæ–‡ä»¶å‘½åï¼‰
        :return: ç”Ÿæˆçš„å›¾ç‰‡æ–‡ä»¶è·¯å¾„ï¼Œå¤±è´¥æ—¶è¿”å›None
        """
        if not self.enable_visualization or root_node is None:
            return None

        try:
            # æ„é€ æ–‡ä»¶å
            if metadata:
                depth = metadata.get('reasoning_depth', 0)
                var_count = metadata.get('variables_count', 0)
                filename = f"dag_sample_{sample_id}_depth{depth}_vars{var_count}"
            else:
                filename = f"dag_sample_{sample_id}"

            # å®Œæ•´è¾“å‡ºè·¯å¾„ï¼ˆä¸åŒ…å«æ‰©å±•åï¼Œvisualize_dagä¼šè‡ªåŠ¨æ·»åŠ ï¼‰
            output_path = os.path.join(self.viz_output_dir, filename)

            # è°ƒç”¨å¯è§†åŒ–å‡½æ•°ï¼ˆä½¿ç”¨ç°ä»£é£æ ¼ï¼‰
            visualize_dag(root_node, filename=output_path, format="png", style="modern")

            final_path = f"{output_path}.png"
            self.logger.info(f"ğŸ¨ DAGå¯è§†åŒ–å·²ç”Ÿæˆ: {final_path}")

            return final_path

        except Exception as e:
            self.logger.warning(f"âš ï¸ ç”ŸæˆDAGå¯è§†åŒ–å¤±è´¥: {e}")
            return None

    def _extract_variables_from_dag(self, root_node) -> List[str]:
        """ä»DAGä¸­æå–å˜é‡ï¼ˆå¸¦æ•°é‡æ§åˆ¶ï¼‰"""
        try:
            variables = self.extractor.extract_from_dag(root_node)

            if variables:
                stats = self.extractor.get_variable_statistics(variables)
                self.logger.info(f"å˜é‡æå–ç»Ÿè®¡: {stats['total_count']} ä¸ªå˜é‡")
                self.logger.debug(f"è¯¦ç»†ç»Ÿè®¡: {stats}")

                # æ£€æŸ¥å˜é‡æ•°é‡æ˜¯å¦åœ¨åˆç†èŒƒå›´å†…
                if stats['total_count'] > self.max_variables:
                    self.logger.warning(f"å˜é‡æ•°é‡è¿‡å¤š ({stats['total_count']} > {self.max_variables})")
                elif stats['total_count'] < self.min_variables:
                    self.logger.warning(f"å˜é‡æ•°é‡å¤ªå°‘ ({stats['total_count']} < {self.min_variables})")
                else:
                    self.logger.info(f"âœ… å˜é‡æ•°é‡åˆé€‚: {stats['total_count']} ä¸ª")

                # è§„èŒƒåŒ–å˜é‡å
                normalized_vars = self.extractor.normalize_variable_names(variables)
                self.logger.debug(f"æå–åˆ°å˜é‡: {normalized_vars}")

                return normalized_vars
            else:
                self.logger.warning("æœªèƒ½ä»DAGä¸­æå–åˆ°ä»»ä½•å˜é‡")
                return []

        except Exception as e:
            self.logger.error(f"å˜é‡æå–å¤±è´¥: {e}")
            return []

    def _extract_variables_from_steps(self, logical_steps: List[Dict]) -> List[str]:
        """ä»é€»è¾‘æ­¥éª¤ä¸­æå–å˜é‡ï¼ˆå¤‡ç”¨æ–¹æ³•ï¼Œå¸¦æ•°é‡æ§åˆ¶ï¼‰"""
        try:
            variables = self.extractor.extract_from_steps(logical_steps)
            if variables:
                stats = self.extractor.get_variable_statistics(variables)
                self.logger.info(f"ä»æ­¥éª¤ä¸­æå– {stats['total_count']} ä¸ªå˜é‡")

                normalized_vars = self.extractor.normalize_variable_names(variables)
                self.logger.debug(f"ä»æ­¥éª¤ä¸­æå–åˆ°å˜é‡: {normalized_vars}")
                return normalized_vars
            return []
        except Exception as e:
            self.logger.error(f"ä»æ­¥éª¤æå–å˜é‡å¤±è´¥: {e}")
            return []

    def _generate_semantic_bindings(self, variables: List[str]) -> Dict[str, str]:
        """
        ä¸ºå˜é‡ç”Ÿæˆå¢å¼ºçš„è¯­ä¹‰ç»‘å®šï¼Œç¡®ä¿è¯­ä¹‰åŸŸä¸€è‡´æ€§
        ç‰¹åˆ«é’ˆå¯¹å˜é‡æ•°é‡æ§åˆ¶åçš„æƒ…å†µä¼˜åŒ–
        """

        # æ‰©å±•çš„è¯­ä¹‰åŸŸï¼Œæä¾›æ›´å¤šé«˜è´¨é‡çš„è¯­ä¹‰æœ¯è¯­
        semantic_domains = {
            "academic_evaluation": {
                "domain_name": "å­¦æœ¯è¯„ä¼°",
                "variables": [
                    "completed_coursework", "passed_examinations", "submitted_thesis",
                    "attended_seminars", "received_approval", "qualified_for_degree",
                    "defended_research", "earned_certification", "published_work",
                    "won_recognition", "met_requirements", "achieved_standards"
                ],
                "context_template": "å­¦æœ¯è¯„ä¼°ç³»ç»Ÿä¸­çš„å­¦ç”Ÿè¡¨ç°è¯„ä»·"
            },
            "business_workflow": {
                "domain_name": "å•†ä¸šæµç¨‹",
                "variables": [
                    "project_initiated", "budget_approved", "team_assembled",
                    "milestone_achieved", "client_satisfied", "contract_finalized",
                    "payment_processed", "quality_verified", "deadline_met",
                    "profit_realized", "objectives_completed", "standards_exceeded"
                ],
                "context_template": "ä¼ä¸šé¡¹ç›®ç®¡ç†å’Œä¸šåŠ¡æµç¨‹"
            },
            "legal_procedure": {
                "domain_name": "æ³•å¾‹ç¨‹åº",
                "variables": [
                    "evidence_presented", "witness_examined", "case_documented",
                    "hearing_conducted", "motion_approved", "settlement_negotiated",
                    "judgment_issued", "appeal_processed", "precedent_established",
                    "verdict_finalized", "ruling_upheld", "procedure_followed"
                ],
                "context_template": "æ³•å¾‹è¯‰è®¼ç¨‹åºå’Œæ¡ˆä»¶å¤„ç†"
            },
            "medical_diagnosis": {
                "domain_name": "åŒ»ç–—è¯Šæ–­",
                "variables": [
                    "symptoms_documented", "tests_performed", "results_interpreted",
                    "diagnosis_established", "treatment_prescribed", "patient_improved",
                    "recovery_achieved", "followup_completed", "clearance_obtained",
                    "discharge_authorized", "medication_effective", "vitals_stable"
                ],
                "context_template": "åŒ»ç–—è¯Šæ–­å’Œæ²»ç–—æµç¨‹"
            },
            "certification_process": {
                "domain_name": "è®¤è¯æµç¨‹",
                "variables": [
                    "training_finished", "examination_passed", "experience_documented",
                    "application_processed", "review_completed", "interview_cleared",
                    "certification_awarded", "license_granted", "renewal_scheduled",
                    "compliance_verified", "standards_met", "credentials_validated"
                ],
                "context_template": "ä¸“ä¸šè®¤è¯å’Œèµ„è´¨è·å–æµç¨‹"
            }
        }

        # éšæœºé€‰æ‹©ä¸€ä¸ªè¯­ä¹‰åŸŸ
        domain_key = random.choice(list(semantic_domains.keys()))
        domain = semantic_domains[domain_key]

        self.logger.info(f"é€‰æ‹©è¯­ä¹‰åŸŸ: {domain['domain_name']}")

        bindings = {}
        domain_vars = domain["variables"]

        # ä¸ºæ¯ä¸ªå˜é‡åˆ†é…è¯­ä¹‰ç»‘å®šï¼ˆç°åœ¨å˜é‡æ•°é‡å·²æ§åˆ¶åœ¨åˆç†èŒƒå›´å†…ï¼‰
        for i, var in enumerate(variables):
            if i < len(domain_vars):
                # ç›´æ¥ä½¿ç”¨åŸŸå†…çš„è¯­ä¹‰æœ¯è¯­
                bindings[var] = domain_vars[i]
            else:
                # å¦‚æœå˜é‡æ•°é‡è¶…è¿‡åŸŸå†…æœ¯è¯­ï¼Œä½¿ç”¨æ›´å…·ä½“çš„å‘½åè€Œä¸æ˜¯é€šç”¨æ ¼å¼
                extra_terms = [
                    f"additional_{domain['domain_name'].lower()}_requirement",
                    f"supplementary_{domain['domain_name'].lower()}_condition",
                    f"extended_{domain['domain_name'].lower()}_criterion",
                    f"further_{domain['domain_name'].lower()}_standard"
                ]
                extra_index = (i - len(domain_vars)) % len(extra_terms)
                bindings[var] = f"{extra_terms[extra_index]}_{i - len(domain_vars) + 1}"

        return bindings

    def _format_z3_expressions(self, logical_steps: List[Dict], var_bindings: Dict[str, str]) -> List[str]:
        """æ”¹è¿›çš„Z3è¡¨è¾¾å¼æ ¼å¼åŒ–ï¼ˆä¼˜åŒ–å˜é‡æ•°é‡æ§åˆ¶åçš„æƒ…å†µï¼‰"""
        z3_exprs = []

        try:
            # 1. å˜é‡å£°æ˜ï¼ˆä½¿ç”¨è¯­ä¹‰åŒ–å˜é‡åï¼‰
            for var, semantic in var_bindings.items():
                z3_exprs.append(f"{semantic} = Bool('{semantic}')")

            # 2. è§„åˆ™è¡¨è¾¾å¼ï¼ˆä¼˜åŒ–å¤„ç†ï¼‰
            processed_expressions = set()  # é¿å…é‡å¤è¡¨è¾¾å¼

            for step in logical_steps:
                try:
                    premises_expr = step.get('premises_expr', [])
                    conclusion_expr = step.get('conclusion_expr')
                    rule_name = step.get('rule', 'Unknown')

                    if not premises_expr or conclusion_expr is None:
                        continue

                    # å®‰å…¨åœ°è½¬æ¢è¡¨è¾¾å¼ä¸ºå­—ç¬¦ä¸²
                    premise_strs = []
                    for premise in premises_expr:
                        try:
                            premise_str = str(premise)
                            # æ›¿æ¢å˜é‡åä¸ºè¯­ä¹‰å
                            for var, semantic in var_bindings.items():
                                premise_str = premise_str.replace(var, semantic)
                            premise_strs.append(premise_str)
                        except Exception as e:
                            self.logger.debug(f"è½¬æ¢å‰æè¡¨è¾¾å¼å¤±è´¥: {e}")
                            continue

                    if not premise_strs:
                        continue

                    # è½¬æ¢ç»“è®ºè¡¨è¾¾å¼
                    try:
                        conclusion_str = str(conclusion_expr)
                        for var, semantic in var_bindings.items():
                            conclusion_str = conclusion_str.replace(var, semantic)
                    except Exception as e:
                        self.logger.debug(f"è½¬æ¢ç»“è®ºè¡¨è¾¾å¼å¤±è´¥: {e}")
                        continue

                    # æ„é€ è•´å«å…³ç³»
                    if len(premise_strs) == 1:
                        implication = f"Implies({premise_strs[0]}, {conclusion_str})"
                    else:
                        premises_conjunction = f"And({', '.join(premise_strs)})"
                        implication = f"Implies({premises_conjunction}, {conclusion_str})"

                    # é¿å…é‡å¤å’Œæ’ç­‰å¼
                    if implication not in processed_expressions and not self._is_tautology(implication):
                        z3_exprs.append(implication)
                        processed_expressions.add(implication)

                except Exception as e:
                    self.logger.debug(f"å¤„ç†é€»è¾‘æ­¥éª¤æ—¶å‡ºé”™: {e}")
                    continue

        except Exception as e:
            self.logger.error(f"æ ¼å¼åŒ–Z3è¡¨è¾¾å¼æ—¶å‡ºé”™: {e}")

        return z3_exprs

    def _is_tautology(self, implication: str) -> bool:
        """æ£€æµ‹æ˜¯å¦ä¸ºæ’ç­‰å¼"""
        try:
            # ç®€å•çš„æ’ç­‰å¼æ£€æµ‹
            if "Implies(" in implication and implication.count(",") >= 1:
                # æå–å‰æå’Œç»“è®ºéƒ¨åˆ†
                start = implication.find("Implies(") + 8
                parts = implication[start:-1].split(", ", 1)
                if len(parts) == 2:
                    premise_part = parts[0].strip()
                    conclusion_part = parts[1].strip()

                    # æ£€æŸ¥æ˜¯å¦ä¸º A -> A æˆ– Aâˆ§Bâˆ§C -> A ç±»å‹çš„æ’ç­‰å¼
                    if premise_part == conclusion_part:
                        return True

                    # æ£€æŸ¥ And(A,B,C) -> A ç±»å‹çš„æ’ç­‰å¼
                    if premise_part.startswith("And(") and conclusion_part in premise_part:
                        return True

            return False
        except:
            return False

    def _create_distractors(self, logical_steps: List[Dict], var_bindings: Dict[str, str]) -> List[str]:
        """åˆ›å»ºå¢å¼ºçš„å¹²æ‰°é¡¹ï¼ˆé€‚é…å˜é‡æ•°é‡æ§åˆ¶ï¼‰"""
        try:
            # åˆ›å»ºå®‰å…¨çš„å¸ƒå°”å˜é‡
            var_names = list(var_bindings.keys())
            safe_vars = self.extractor.create_safe_bool_vars(var_names)

            if not safe_vars:
                self.logger.warning("æ— æ³•åˆ›å»ºæœ‰æ•ˆçš„å¸ƒå°”å˜é‡ï¼Œä½¿ç”¨å›é€€å¹²æ‰°é¡¹")
                return self._create_fallback_distractors()

            # ç”Ÿæˆå¹²æ‰°é¡¹
            distractor_gen = DistractorGenerator(
                available_vars=safe_vars,
                enabled_strategies=["illogical_reasoning", "adversarial_structure", "reversed_implication"]
            )

            distractors = distractor_gen.generate_all(logical_steps, num_per_strategy=2)

            # è½¬æ¢ä¸ºè‡ªç„¶è¯­è¨€æè¿°
            distractor_descriptions = []
            for d in distractors[:3]:  # æœ€å¤š3ä¸ªå¹²æ‰°é¡¹
                desc = d.get('description', f"åŸºäº{d.get('strategy', 'unknown')}ç­–ç•¥çš„å¹²æ‰°é¡¹")
                distractor_descriptions.append(desc)

            return distractor_descriptions

        except Exception as e:
            self.logger.warning(f"ç”Ÿæˆå¹²æ‰°é¡¹å¤±è´¥: {e}")
            return self._create_fallback_distractors()

    def _create_fallback_distractors(self) -> List[str]:
        """åˆ›å»ºå¤‡ç”¨å¹²æ‰°é¡¹"""
        return [
            "åŸºäºä¸å®Œæ•´å‰æçš„é”™è¯¯æ¨ç†",
            "é€»è¾‘æ–¹å‘é¢ å€’çš„é”™è¯¯ç»“è®º",
            "æ— å…³æ¡ä»¶çš„å¹²æ‰°æ€§æ¨æ–­"
        ]

    def generate_single_sample(self, max_depth: int = 3, sample_id: Optional[str] = None) -> Optional[Dict[str, Any]]:
        """
        ç”Ÿæˆå•ä¸ªæ•°æ®æ ·æœ¬ï¼ˆä¸¥æ ¼æ§åˆ¶å˜é‡æ•°é‡ + é›†æˆå¯è§†åŒ–ï¼‰

        :param max_depth: æœ€å¤§æ¨ç†æ·±åº¦
        :param sample_id: æ ·æœ¬å”¯ä¸€æ ‡è¯†ç¬¦ï¼ˆç”¨äºæ–‡ä»¶å‘½åï¼‰
        :return: ç”Ÿæˆçš„æ ·æœ¬æ•°æ®
        """
        # å¦‚æœæ²¡æœ‰æä¾›sample_idï¼Œè‡ªåŠ¨ç”Ÿæˆ
        if sample_id is None:
            sample_id = f"{random.randint(10000, 99999)}"

        for attempt in range(self.max_retry_attempts):
            try:
                # 1. æ„å»ºæ¨ç†DAG
                self.logger.info(f"æ„å»ºæ¨ç†DAGï¼Œæ·±åº¦={max_depth}ï¼Œå°è¯•{attempt + 1}")
                root, logical_steps = build_reasoning_dag(max_depth=max_depth, min_depth=max(max_depth // 3, 2))

                if not logical_steps:
                    self.logger.warning("æœªèƒ½ç”Ÿæˆé€»è¾‘æ­¥éª¤ï¼Œé‡è¯•")
                    continue

                # 2. éªŒè¯é€»è¾‘æ­¥éª¤
                valid_steps, failed_steps = validate_logical_steps(logical_steps)

                if len(valid_steps) < self.min_valid_steps:
                    self.logger.warning(f"æœ‰æ•ˆæ­¥éª¤å¤ªå°‘ ({len(valid_steps)} < {self.min_valid_steps})ï¼Œé‡è¯•")
                    continue

                if len(valid_steps) > self.max_valid_steps:
                    valid_steps = valid_steps[:self.max_valid_steps]

                self.logger.info(f"æˆåŠŸéªŒè¯ {len(valid_steps)} ä¸ªé€»è¾‘æ­¥éª¤")

                # 3. æå–å˜é‡å’Œç”Ÿæˆè¯­ä¹‰ç»‘å®šï¼ˆä¸¥æ ¼æ§åˆ¶æ•°é‡ï¼‰
                variables = self._extract_variables_from_dag(root)

                # å¦‚æœDAGæå–å¤±è´¥ï¼Œå°è¯•ä»æ­¥éª¤ä¸­æå–
                if not variables:
                    self.logger.info("å°è¯•ä»é€»è¾‘æ­¥éª¤ä¸­æå–å˜é‡...")
                    variables = self._extract_variables_from_steps(valid_steps)

                if not variables:
                    self.logger.warning("æœªèƒ½æå–åˆ°å˜é‡ï¼Œé‡è¯•")
                    continue

                # å†æ¬¡æ£€æŸ¥å˜é‡æ•°é‡
                if len(variables) > self.max_variables:
                    self.logger.warning(f"å˜é‡æ•°é‡ä»ç„¶è¿‡å¤š ({len(variables)} > {self.max_variables})ï¼Œé‡è¯•")
                    continue

                if len(variables) < self.min_variables:
                    self.logger.warning(f"å˜é‡æ•°é‡å¤ªå°‘ ({len(variables)} < {self.min_variables})ï¼Œé‡è¯•")
                    continue

                var_bindings = self._generate_semantic_bindings(variables)
                self.logger.info(f"âœ… ç”Ÿæˆ {len(var_bindings)} ä¸ªå˜é‡ç»‘å®šï¼ˆåœ¨åˆç†èŒƒå›´å†…ï¼‰")

                # 4. æ„å»ºå¢å¼ºprompt
                enhanced_prompt = self.prompt_builder.build_constrained_prompt(
                    z3_exprs=self._format_z3_expressions(valid_steps, var_bindings),
                    var_bindings=var_bindings,
                    logical_steps=valid_steps,
                    previous_violations=[]
                )

                # 5. è°ƒç”¨LLM
                self.logger.info("è°ƒç”¨LLMç”Ÿæˆé¢˜ç›®...")
                response = self.llm.call(enhanced_prompt)

                if not response:
                    self.logger.error("LLMå“åº”ä¸ºç©ºï¼Œé‡è¯•")
                    continue

                # 6. è§£æå“åº”
                sample = self._parse_llm_response(response, valid_steps, var_bindings)
                if not sample:
                    self.logger.error("å“åº”è§£æå¤±è´¥ï¼Œé‡è¯•")
                    continue

                # 7. è´¨é‡éªŒè¯
                is_valid, violations = self.validator.validate_sample(sample)

                if is_valid:
                    self.logger.info("âœ… æ ·æœ¬é€šè¿‡è´¨é‡éªŒè¯")

                    # 8. æ·»åŠ å…ƒæ•°æ®
                    final_sample = self._add_metadata(sample, valid_steps, var_bindings)

                    # 9. ğŸ¨ ç”ŸæˆDAGå¯è§†åŒ–å›¾ç‰‡
                    if root is not None:
                        viz_path = self._generate_dag_visualization(
                            root_node=root,
                            sample_id=sample_id,
                            metadata=final_sample.get('metadata', {})
                        )

                        # å°†å¯è§†åŒ–è·¯å¾„æ·»åŠ åˆ°æ ·æœ¬æ•°æ®ä¸­
                        if viz_path:
                            final_sample['visualization_path'] = viz_path

                    return final_sample
                else:
                    self.logger.warning(f"âš ï¸ è´¨é‡éªŒè¯å¤±è´¥: {violations}")
                    # åœ¨æœ€åä¸€æ¬¡å°è¯•æ—¶ï¼Œè¿”å›éƒ¨åˆ†åˆæ ¼çš„æ ·æœ¬
                    if attempt == self.max_retry_attempts - 1:
                        sample['validation_warnings'] = violations
                        final_sample = self._add_metadata(sample, valid_steps, var_bindings)

                        # å³ä½¿éªŒè¯å¤±è´¥ï¼Œä¹Ÿç”Ÿæˆå¯è§†åŒ–
                        if root is not None:
                            viz_path = self._generate_dag_visualization(
                                root_node=root,
                                sample_id=f"{sample_id}_partial",
                                metadata=final_sample.get('metadata', {})
                            )
                            if viz_path:
                                final_sample['visualization_path'] = viz_path

                        return final_sample

            except Exception as e:
                self.logger.error(f"ç”Ÿæˆæ ·æœ¬æ—¶å‡ºé”™ (å°è¯• {attempt + 1}): {e}")
                continue

        self.logger.error("æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥")
        return None

    def _parse_llm_response(self, response: str, valid_steps: List[Dict], var_bindings: Dict[str, str]) -> \
            Optional[Dict]:
        """æ”¹è¿›çš„LLMå“åº”è§£æ"""
        try:
            # æå–JSONéƒ¨åˆ†
            json_start = response.find('{')
            json_end = response.rfind('}') + 1

            if json_start == -1 or json_end <= json_start:
                self.logger.error("å“åº”ä¸­æœªæ‰¾åˆ°æœ‰æ•ˆJSON")
                return None

            json_str = response[json_start:json_end]

            # è§£æJSON
            result = json.loads(json_str)

            # éªŒè¯å¿…éœ€å­—æ®µ
            required_fields = ["context", "question", "answers", "label", "z3"]
            for field in required_fields:
                if field not in result:
                    self.logger.error(f"å“åº”ç¼ºå°‘å¿…éœ€å­—æ®µ: {field}")
                    return None

            # éªŒè¯answersæ ¼å¼
            if not isinstance(result["answers"], list) or len(result["answers"]) != 4:
                self.logger.error(f"ç­”æ¡ˆé€‰é¡¹æ ¼å¼é”™è¯¯: {result.get('answers')}")
                return None

            # éªŒè¯labelæ ¼å¼
            if result["label"] not in ["A", "B", "C", "D"]:
                self.logger.error(f"æ ‡ç­¾æ ¼å¼é”™è¯¯: {result.get('label')}")
                return None

            return result

        except json.JSONDecodeError as e:
            self.logger.error(f"JSONè§£æå¤±è´¥: {e}")
            # å°è¯•ä¿®å¤å¸¸è§çš„JSONé”™è¯¯
            return self._try_fix_json(json_str)
        except Exception as e:
            self.logger.error(f"è§£æå“åº”æ—¶å‡ºé”™: {e}")
            return None

    def _try_fix_json(self, json_str: str) -> Optional[Dict]:
        """å°è¯•ä¿®å¤å¸¸è§çš„JSONé”™è¯¯"""
        try:
            # ä¿®å¤å¸¸è§é—®é¢˜ï¼šå¤šä½™çš„é€—å·ã€å¼•å·é—®é¢˜ç­‰
            fixed_json = json_str.replace(',]', ']').replace(',}', '}')
            # å°è¯•å†æ¬¡è§£æ
            return json.loads(fixed_json)
        except:
            return None

    def _add_metadata(self, sample: Dict, valid_steps: List[Dict], var_bindings: Dict[str, str]) -> Dict:
        """æ·»åŠ å¢å¼ºçš„å…ƒæ•°æ®"""
        sample['metadata'] = {
            'reasoning_depth': len(valid_steps),
            'variables_count': len(var_bindings),
            'rules_used': [step.get('rule', 'Unknown') for step in valid_steps],
            'semantic_domain': self._infer_semantic_domain(var_bindings),
            'logical_complexity': self._calculate_complexity(valid_steps),
            'generation_version': 'variable_controlled_v2_with_matplotlib_viz',
            'variable_extraction_method': 'enhanced_extractor_with_control',
            'variable_control': {
                'max_variables': self.max_variables,
                'min_variables': self.min_variables,
                'actual_variables': len(var_bindings),
                'within_limits': self.min_variables <= len(var_bindings) <= self.max_variables
            },
            'visualization_enabled': self.enable_visualization
        }

        # æ·»åŠ è´¨é‡åˆ†æ•°
        sample['quality_score'] = self._calculate_quality_score(sample)

        return sample

    def _infer_semantic_domain(self, var_bindings: Dict[str, str]) -> str:
        """æ¨æ–­è¯­ä¹‰åŸŸ"""
        all_bindings = " ".join(var_bindings.values()).lower()

        domain_keywords = {
            "academic": ["coursework", "examination", "thesis", "seminar", "degree", "research"],
            "business": ["project", "budget", "team", "milestone", "client", "contract"],
            "legal": ["evidence", "witness", "case", "hearing", "motion", "settlement"],
            "medical": ["symptoms", "tests", "diagnosis", "treatment", "patient", "recovery"],
            "certification": ["training", "examination", "experience", "application", "certification"]
        }

        for domain, keywords in domain_keywords.items():
            if any(keyword in all_bindings for keyword in keywords):
                return domain

        return "general"

    def _calculate_complexity(self, valid_steps: List[Dict]) -> str:
        """è®¡ç®—é€»è¾‘å¤æ‚åº¦"""
        step_count = len(valid_steps)

        if step_count <= 2:
            return "simple"
        elif step_count <= 4:
            return "medium"
        else:
            return "complex"

    def _calculate_quality_score(self, sample: Dict) -> float:
        """è®¡ç®—è´¨é‡åˆ†æ•° (0-1)"""
        score = 0.0

        # åŸºç¡€åˆ†æ•°
        score += 0.3

        # è¯­ä¹‰ä¸€è‡´æ€§
        if 'validation_warnings' not in sample:
            score += 0.3

        # é€»è¾‘æ·±åº¦
        depth = sample.get('metadata', {}).get('reasoning_depth', 0)
        score += min(depth / 6, 0.2)  # æœ€å¤š0.2åˆ†

        # å˜é‡ä½¿ç”¨ï¼ˆç°åœ¨æ›´é‡è¦äº†ï¼‰
        var_control = sample.get('metadata', {}).get('variable_control', {})
        if var_control.get('within_limits', False):
            score += 0.2  # å˜é‡æ•°é‡åœ¨åˆç†èŒƒå›´å†…

        return min(score, 1.0)

    def generate_dataset(self, num_samples: int, output_path: str, max_depth_range: tuple = (5, 8)) -> None:
        """
        ç”Ÿæˆå®Œæ•´æ•°æ®é›†ï¼ˆå˜é‡æ•°é‡æ§åˆ¶ç‰ˆ + matplotlibå¯è§†åŒ–ï¼‰

        :param num_samples: ç”Ÿæˆæ ·æœ¬æ•°é‡
        :param output_path: æ•°æ®é›†è¾“å‡ºè·¯å¾„
        :param max_depth_range: æ¨ç†æ·±åº¦èŒƒå›´
        """
        self.logger.info(
            f"å¼€å§‹ç”Ÿæˆ {num_samples} ä¸ªæ ·æœ¬çš„æ•°æ®é›†ï¼ˆå˜é‡æ•°é‡æ§åˆ¶: {self.min_variables}-{self.max_variables}ï¼‰")
        self.logger.info(f"å¯è§†åŒ–åŠŸèƒ½: {'âœ… å¯ç”¨ (matplotlib)' if self.enable_visualization else 'âŒ ç¦ç”¨'}")

        Path(output_path).parent.mkdir(parents=True, exist_ok=True)

        successful_samples = []
        attempts = 0
        max_attempts = num_samples * 4

        # ç»Ÿè®¡ä¿¡æ¯
        stats = {
            "total_attempts": 0,
            "successful": 0,
            "failed": 0,
            "quality_scores": [],
            "semantic_domains": {},
            "complexity_levels": {},
            "variable_control_stats": {
                "avg_variables": 0,
                "within_limits_count": 0,
                "over_limit_count": 0,
                "under_limit_count": 0
            },
            "visualization_stats": {
                "enabled": self.enable_visualization,
                "generated_count": 0,
                "failed_count": 0,
                "output_directory": self.viz_output_dir if self.enable_visualization else None,
                "visualization_engine": "matplotlib + networkx"
            }
        }

        while len(successful_samples) < num_samples and attempts < max_attempts:
            attempts += 1
            stats["total_attempts"] += 1

            # å¯¹äºå˜é‡æ•°é‡æ§åˆ¶ï¼Œé€‚å½“é™ä½æ·±åº¦èŒƒå›´
            depth = random.randint(*max_depth_range)

            self.logger.info(f"ç”Ÿæˆæ ·æœ¬ {len(successful_samples) + 1}/{num_samples} (å°è¯• {attempts})")

            # ç”Ÿæˆå”¯ä¸€çš„æ ·æœ¬ID
            sample_id = f"sample_{len(successful_samples) + 1:04d}_{attempts:04d}"

            sample = self.generate_single_sample(max_depth=depth, sample_id=sample_id)

            if sample:
                successful_samples.append(sample)
                stats["successful"] += 1

                # æ”¶é›†ç»Ÿè®¡ä¿¡æ¯
                quality_score = sample.get('quality_score', 0)
                stats["quality_scores"].append(quality_score)

                domain = sample.get('metadata', {}).get('semantic_domain', 'unknown')
                stats["semantic_domains"][domain] = stats["semantic_domains"].get(domain, 0) + 1

                complexity = sample.get('metadata', {}).get('logical_complexity', 'unknown')
                stats["complexity_levels"][complexity] = stats["complexity_levels"].get(complexity, 0) + 1

                # å˜é‡æ§åˆ¶ç»Ÿè®¡
                var_control = sample.get('metadata', {}).get('variable_control', {})
                actual_vars = var_control.get('actual_variables', 0)
                stats["variable_control_stats"]["avg_variables"] += actual_vars

                if var_control.get('within_limits', False):
                    stats["variable_control_stats"]["within_limits_count"] += 1
                elif actual_vars > self.max_variables:
                    stats["variable_control_stats"]["over_limit_count"] += 1
                else:
                    stats["variable_control_stats"]["under_limit_count"] += 1

                # å¯è§†åŒ–ç»Ÿè®¡
                if 'visualization_path' in sample:
                    stats["visualization_stats"]["generated_count"] += 1
                    self.logger.info(f"ğŸ¨ å¯è§†åŒ–æ–‡ä»¶: {sample['visualization_path']}")
                else:
                    stats["visualization_stats"]["failed_count"] += 1

                self.logger.info(
                    f"âœ… æˆåŠŸç”Ÿæˆæ ·æœ¬ {len(successful_samples)} (è´¨é‡åˆ†æ•°: {quality_score:.2f}, å˜é‡: {actual_vars})")

            else:
                stats["failed"] += 1
                self.logger.warning(f"âŒ æ ·æœ¬ç”Ÿæˆå¤±è´¥ (å°è¯• {attempts})")

        # è®¡ç®—å¹³å‡å˜é‡æ•°é‡
        if stats["successful"] > 0:
            stats["variable_control_stats"]["avg_variables"] /= stats["successful"]

        # ä¿å­˜æ•°æ®é›†
        self._save_dataset_with_stats(successful_samples, stats, output_path)

        # è¾“å‡ºæœ€ç»ˆç»Ÿè®¡
        self._print_final_statistics(stats)

    def _save_dataset_with_stats(self, samples: List[Dict], stats: Dict, output_path: str):
        """ä¿å­˜æ•°æ®é›†å¹¶åŒ…å«ç»Ÿè®¡ä¿¡æ¯"""
        # ä¿å­˜æ•°æ®é›†
        with open(output_path, 'w', encoding='utf-8') as f:
            for sample in samples:
                f.write(json.dumps(sample, ensure_ascii=False) + '\n')

        # ä¿å­˜ç»Ÿè®¡ä¿¡æ¯
        stats_path = output_path.replace('.jsonl', '_stats.json')
        with open(stats_path, 'w', encoding='utf-8') as f:
            json.dump(stats, f, ensure_ascii=False, indent=2)

        self.logger.info(f"æ•°æ®é›†å·²ä¿å­˜: {output_path}")
        self.logger.info(f"ç»Ÿè®¡ä¿¡æ¯å·²ä¿å­˜: {stats_path}")

    def _print_final_statistics(self, stats: Dict):
        """æ‰“å°æœ€ç»ˆç»Ÿè®¡ä¿¡æ¯"""
        success_rate = stats["successful"] / stats["total_attempts"] * 100 if stats["total_attempts"] > 0 else 0
        avg_quality = sum(stats["quality_scores"]) / len(stats["quality_scores"]) if stats["quality_scores"] else 0

        self.logger.info("=" * 60)
        self.logger.info("ğŸ“Š æ•°æ®é›†ç”Ÿæˆç»Ÿè®¡ï¼ˆå˜é‡æ•°é‡æ§åˆ¶ç‰ˆ + matplotlibå¯è§†åŒ–ï¼‰")
        self.logger.info(f"æˆåŠŸç‡: {success_rate:.1f}% ({stats['successful']}/{stats['total_attempts']})")
        self.logger.info(f"å¹³å‡è´¨é‡åˆ†æ•°: {avg_quality:.3f}")
        self.logger.info(f"è¯­ä¹‰åŸŸåˆ†å¸ƒ: {stats['semantic_domains']}")
        self.logger.info(f"å¤æ‚åº¦åˆ†å¸ƒ: {stats['complexity_levels']}")

        # å˜é‡æ§åˆ¶ç»Ÿè®¡
        var_stats = stats["variable_control_stats"]
        self.logger.info("ğŸ¯ å˜é‡æ§åˆ¶ç»Ÿè®¡:")
        self.logger.info(f"  å¹³å‡å˜é‡æ•°é‡: {var_stats['avg_variables']:.1f}")
        self.logger.info(f"  èŒƒå›´å†…æ ·æœ¬: {var_stats['within_limits_count']}")
        self.logger.info(f"  è¶…å‡ºä¸Šé™: {var_stats['over_limit_count']}")
        self.logger.info(f"  ä½äºä¸‹é™: {var_stats['under_limit_count']}")
        self.logger.info(f"  ç›®æ ‡èŒƒå›´: {self.min_variables}-{self.max_variables}")

        # å¯è§†åŒ–ç»Ÿè®¡
        viz_stats = stats["visualization_stats"]
        self.logger.info("ğŸ¨ å¯è§†åŒ–ç»Ÿè®¡:")
        self.logger.info(f"  åŠŸèƒ½çŠ¶æ€: {'å¯ç”¨' if viz_stats['enabled'] else 'ç¦ç”¨'}")
        self.logger.info(f"  å¯è§†åŒ–å¼•æ“: {viz_stats.get('visualization_engine', 'Unknown')}")
        if viz_stats['enabled']:
            self.logger.info(f"  æˆåŠŸç”Ÿæˆ: {viz_stats['generated_count']}")
            self.logger.info(f"  ç”Ÿæˆå¤±è´¥: {viz_stats['failed_count']}")
            self.logger.info(f"  è¾“å‡ºç›®å½•: {viz_stats['output_directory']}")
            viz_success_rate = (viz_stats['generated_count'] /
                                (viz_stats['generated_count'] + viz_stats['failed_count']) * 100
                                if (viz_stats['generated_count'] + viz_stats['failed_count']) > 0 else 0)
            self.logger.info(f"  å¯è§†åŒ–æˆåŠŸç‡: {viz_success_rate:.1f}%")

        self.logger.info("=" * 60)

    def generate_sample_with_custom_visualization(
            self,
            max_depth: int = 3,
            sample_id: Optional[str] = None,
            viz_style: str = "modern",
            viz_format: str = "png"
    ) -> Optional[Dict[str, Any]]:
        """
        ç”Ÿæˆå•ä¸ªæ ·æœ¬å¹¶è‡ªå®šä¹‰å¯è§†åŒ–é€‰é¡¹

        :param max_depth: æœ€å¤§æ¨ç†æ·±åº¦
        :param sample_id: æ ·æœ¬ID
        :param viz_style: å¯è§†åŒ–é£æ ¼ ("modern", "classic", "minimal")
        :param viz_format: å¯è§†åŒ–æ ¼å¼ ("png", "pdf", "svg")
        :return: æ ·æœ¬æ•°æ®
        """
        if sample_id is None:
            sample_id = f"custom_{random.randint(1000, 9999)}"

        # ä¸´æ—¶ä¿å­˜åŸå§‹è®¾ç½®
        original_enable = self.enable_visualization

        # å¯ç”¨å¯è§†åŒ–
        self.enable_visualization = True

        try:
            # ç”Ÿæˆæ ·æœ¬
            sample = self.generate_single_sample(max_depth=max_depth, sample_id=sample_id)

            # å¦‚æœæ ·æœ¬ç”ŸæˆæˆåŠŸä¸”éœ€è¦è‡ªå®šä¹‰å¯è§†åŒ–
            if sample and (viz_style != "modern" or viz_format != "png"):
                # è¿™é‡Œéœ€è¦é‡æ–°ç”Ÿæˆå¯è§†åŒ–ï¼Œä½†éœ€è¦ä¿å­˜root_node
                # æ³¨æ„ï¼šå½“å‰å®ç°ä¸­root_nodeæ²¡æœ‰ä¿å­˜åˆ°sampleä¸­
                self.logger.info(f"ğŸ¨ è‡ªå®šä¹‰å¯è§†åŒ–é€‰é¡¹: é£æ ¼={viz_style}, æ ¼å¼={viz_format}")
                self.logger.warning("âš ï¸ è‡ªå®šä¹‰å¯è§†åŒ–éœ€è¦åœ¨generate_single_sampleä¸­ä¿å­˜root_node")

            return sample

        finally:
            # æ¢å¤åŸå§‹è®¾ç½®
            self.enable_visualization = original_enable

    def create_visualization_gallery(self, samples: List[Dict], output_dir: str = "output/gallery"):
        """
        ä¸ºå¤šä¸ªæ ·æœ¬åˆ›å»ºå¯è§†åŒ–ç”»å»Š

        :param samples: æ ·æœ¬åˆ—è¡¨
        :param output_dir: è¾“å‡ºç›®å½•
        """
        try:
            from dag.visualizer import create_comparison_visualization

            Path(output_dir).mkdir(parents=True, exist_ok=True)

            # æ”¶é›†æœ‰å¯è§†åŒ–è·¯å¾„çš„æ ·æœ¬
            viz_samples = [s for s in samples if 'visualization_path' in s]

            if not viz_samples:
                self.logger.warning("æ²¡æœ‰æ‰¾åˆ°åŒ…å«å¯è§†åŒ–çš„æ ·æœ¬")
                return

            # åˆ›å»ºæ‘˜è¦é¡µé¢
            summary_html = self._create_html_summary(viz_samples, output_dir)

            summary_path = os.path.join(output_dir, "visualization_gallery.html")
            with open(summary_path, 'w', encoding='utf-8') as f:
                f.write(summary_html)

            self.logger.info(f"ğŸ¨ å¯è§†åŒ–ç”»å»Šå·²åˆ›å»º: {summary_path}")

        except Exception as e:
            self.logger.error(f"åˆ›å»ºå¯è§†åŒ–ç”»å»Šå¤±è´¥: {e}")

    def _create_html_summary(self, samples: List[Dict], output_dir: str) -> str:
        """åˆ›å»ºHTMLæ‘˜è¦é¡µé¢"""
        html_parts = [
            "<!DOCTYPE html>",
            "<html><head><title>DAG å¯è§†åŒ–ç”»å»Š</title>",
            "<style>",
            "body { font-family: Arial, sans-serif; margin: 20px; }",
            ".sample { border: 1px solid #ccc; margin: 20px 0; padding: 15px; }",
            ".viz-image { max-width: 400px; height: auto; }",
            ".metadata { background: #f5f5f5; padding: 10px; margin: 10px 0; }",
            "</style></head><body>",
            f"<h1>DAG å¯è§†åŒ–ç”»å»Š ({len(samples)} ä¸ªæ ·æœ¬)</h1>"
        ]

        for i, sample in enumerate(samples, 1):
            metadata = sample.get('metadata', {})
            viz_path = sample.get('visualization_path', '')

            # è®¡ç®—ç›¸å¯¹è·¯å¾„
            if viz_path:
                rel_path = os.path.relpath(viz_path, output_dir)
            else:
                rel_path = "æ— å¯è§†åŒ–"

            html_parts.extend([
                f"<div class='sample'>",
                f"<h3>æ ·æœ¬ {i}</h3>",
                f"<img src='{rel_path}' class='viz-image' alt='DAGå¯è§†åŒ–' />",
                f"<div class='metadata'>",
                f"<p><strong>æ¨ç†æ·±åº¦:</strong> {metadata.get('reasoning_depth', 'N/A')}</p>",
                f"<p><strong>å˜é‡æ•°é‡:</strong> {metadata.get('variables_count', 'N/A')}</p>",
                f"<p><strong>è¯­ä¹‰åŸŸ:</strong> {metadata.get('semantic_domain', 'N/A')}</p>",
                f"<p><strong>å¤æ‚åº¦:</strong> {metadata.get('logical_complexity', 'N/A')}</p>",
                f"<p><strong>è´¨é‡åˆ†æ•°:</strong> {sample.get('quality_score', 'N/A'):.3f}</p>",
                f"</div></div>"
            ])

        html_parts.extend(["</body></html>"])
        return '\n'.join(html_parts)


def main():
    """ä¸»å‡½æ•°ç¤ºä¾‹ï¼ˆå˜é‡æ•°é‡æ§åˆ¶ç‰ˆ + matplotlibå¯è§†åŒ–ï¼‰"""
    # é…ç½®æ—¥å¿—
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )

    # åˆå§‹åŒ–LLMè°ƒåº¦å™¨
    llm = LLMDispatcher(
        model_name="deepseek-chat",
        api_key_path="api_key/ds-api_key.txt",
        retries=3
    )

    # åˆå§‹åŒ–å¸¦matplotlibå¯è§†åŒ–åŠŸèƒ½çš„æ•°æ®é›†ç”Ÿæˆå™¨
    generator = DatasetGenerator(
        llm_dispatcher=llm,
        prompt_template_path="prompt/lsat_prompt.txt",
        max_variables=10,  # æœ€å¤§10ä¸ªå˜é‡
        min_variables=3,  # æœ€å°3ä¸ªå˜é‡
        enable_visualization=True,  # å¯ç”¨å¯è§†åŒ–
        viz_output_dir="output/dag_visualizations"  # å¯è§†åŒ–è¾“å‡ºç›®å½•
    )

    # ç”Ÿæˆæ•°æ®é›†ï¼ˆæ¯ä¸ªæ ·æœ¬éƒ½ä¼šè‡ªåŠ¨ç”Ÿæˆå¯¹åº”çš„DAGå›¾ç‰‡ï¼‰
    generator.generate_dataset(
        num_samples=1,  # å…ˆç”Ÿæˆå°‘é‡æ ·æœ¬è¿›è¡Œæµ‹è¯•
        output_path="output/controlled_lsat_dataset_with_matplotlib_viz.jsonl",
        max_depth_range=(8, 10)  # é™ä½æ·±åº¦èŒƒå›´ä»¥ä¾¿å¿«é€Ÿæµ‹è¯•
    )

    # ç¤ºä¾‹ï¼šç”Ÿæˆå•ä¸ªæ ·æœ¬å¹¶è‡ªå®šä¹‰å¯è§†åŒ–
    print("\n" + "=" * 50)
    print("ğŸ¨ ç”Ÿæˆå•ä¸ªæ ·æœ¬å¹¶è‡ªå®šä¹‰å¯è§†åŒ–")
    print("=" * 50)

    single_sample = generator.generate_sample_with_custom_visualization(
        max_depth=10,
        sample_id="demo_matplotlib",
        viz_style="modern",
        viz_format="png"
    )

    if single_sample:
        print(f"âœ… å•ä¸ªæ ·æœ¬ç”ŸæˆæˆåŠŸ")
        if 'visualization_path' in single_sample:
            print(f"ğŸ¨ å¯è§†åŒ–è·¯å¾„: {single_sample['visualization_path']}")
        print(f"ğŸ“Š è´¨é‡åˆ†æ•°: {single_sample.get('quality_score', 0):.3f}")
        print(f"ğŸ”¢ å˜é‡æ•°é‡: {single_sample.get('metadata', {}).get('variables_count', 0)}")
    else:
        print("âŒ å•ä¸ªæ ·æœ¬ç”Ÿæˆå¤±è´¥")


if __name__ == "__main__":
    main()