# æ–‡ä»¶ï¼štest_dataset_generation.py
# è¯´æ˜ï¼šæµ‹è¯•æ•°æ®é›†ç”Ÿæˆæµç¨‹

import logging
import json
from pathlib import Path
from dataset_generator import DatasetGenerator
from api_key.llm_dispatcher import LLMDispatcher


def test_single_sample():
    """æµ‹è¯•å•ä¸ªæ ·æœ¬ç”Ÿæˆ"""
    print("=== ğŸ§ª æµ‹è¯•å•ä¸ªæ ·æœ¬ç”Ÿæˆ ===")

    # é…ç½®æ—¥å¿—
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )

    # æ£€æŸ¥API keyæ–‡ä»¶
    api_key_files = [
        "../api_key/ds-api_key.txt"
    ]

    available_key = "../api_key/ds-api_key.txt"
    model_name = "deepseek-chat"

    for key_file in api_key_files:
        if Path(key_file).exists():
            with open(key_file, 'r') as f:
                key_content = f.read().strip()
                if key_content:
                    available_key = key_file
                    model_name = "gpt4" if "openai" in key_file else "deepseek-chat"
                    print(f"âœ… æ‰¾åˆ°å¯ç”¨çš„API key: {key_file}")
                    break

    if not available_key:
        print("âŒ æœªæ‰¾åˆ°å¯ç”¨çš„API keyæ–‡ä»¶ï¼Œåˆ›å»ºæ¨¡æ‹Ÿå“åº”è¿›è¡Œæµ‹è¯•")
        test_mock_generation()
        return

    try:
        # åˆå§‹åŒ–LLMè°ƒåº¦å™¨
        llm = LLMDispatcher(
            model_name=model_name,
            api_key_path=available_key,
            retries=2
        )

        # æ£€æŸ¥promptæ¨¡æ¿
        prompt_path = "../prompt/lsat_prompt.txt"
        if not Path(prompt_path).exists():
            print(f"âš ï¸  Promptæ¨¡æ¿æ–‡ä»¶ä¸å­˜åœ¨: {prompt_path}")
            print("åˆ›å»ºé»˜è®¤æ¨¡æ¿...")
            create_default_prompt_template(prompt_path)

        # åˆå§‹åŒ–æ•°æ®é›†ç”Ÿæˆå™¨
        generator = DatasetGenerator(
            llm_dispatcher=llm,
            prompt_template_path=prompt_path
        )

        # ç”Ÿæˆå•ä¸ªæ ·æœ¬
        print("\nğŸ”„ ç”Ÿæˆå•ä¸ªæ ·æœ¬...")
        sample = generator.generate_single_sample(max_depth=3)

        if sample:
            print("âœ… æ ·æœ¬ç”ŸæˆæˆåŠŸ!")
            print("\nğŸ“‹ æ ·æœ¬å†…å®¹:")
            print(f"Context: {sample.get('context', 'N/A')[:100]}...")
            print(f"Question: {sample.get('question', 'N/A')[:100]}...")
            print(f"ç­”æ¡ˆæ•°é‡: {len(sample.get('answers', []))}")
            print(f"æ­£ç¡®ç­”æ¡ˆ: {sample.get('label', 'N/A')}")

            # ä¿å­˜æ ·æœ¬
            output_dir = Path("output")
            output_dir.mkdir(exist_ok=True)

            with open(output_dir / "test_sample.json", 'w', encoding='utf-8') as f:
                json.dump(sample, f, ensure_ascii=False, indent=2)

            print(f"\nğŸ’¾ æ ·æœ¬å·²ä¿å­˜åˆ°: {output_dir / 'test_sample.json'}")
        else:
            print("âŒ æ ·æœ¬ç”Ÿæˆå¤±è´¥")

    except Exception as e:
        print(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()


def test_mock_generation():
    """æ¨¡æ‹Ÿç”Ÿæˆè¿‡ç¨‹ï¼ˆä¸è°ƒç”¨å®é™…LLMï¼‰"""
    print("\n=== ğŸ­ æ¨¡æ‹Ÿç”Ÿæˆæµç¨‹æµ‹è¯• ===")

    from dag.dag_builder import build_reasoning_dag
    from dag.validator import validate_logical_steps
    from distractor.generator import DistractorGenerator
    import z3

    try:
        # 1. æ„å»ºæ¨ç†DAG
        print("ğŸ—ï¸  æ„å»ºæ¨ç†DAG...")
        root, logical_steps = build_reasoning_dag(max_depth=3)
        print(f"ç”Ÿæˆäº† {len(logical_steps)} ä¸ªæ¨ç†æ­¥éª¤")

        # 2. éªŒè¯æ­¥éª¤
        print("ğŸ” éªŒè¯æ¨ç†æ­¥éª¤...")
        valid_steps, failed_steps = validate_logical_steps(logical_steps)
        print(f"éªŒè¯é€šè¿‡: {len(valid_steps)} æ­¥, å¤±è´¥: {len(failed_steps)} æ­¥")

        if valid_steps:
            # 3. ç”Ÿæˆå˜é‡ç»‘å®š
            print("ğŸ”— ç”Ÿæˆå˜é‡ç»‘å®š...")
            variables = []
            for step in valid_steps:
                for premise in step.get('premises', []):
                    import re
                    vars_found = re.findall(r'Var_\d+', premise)
                    variables.extend(vars_found)

            variables = sorted(list(set(variables)))
            print(f"æ‰¾åˆ°å˜é‡: {variables[:5]}{'...' if len(variables) > 5 else ''}")

            # 4. ç”Ÿæˆå¹²æ‰°é¡¹
            print("ğŸ¯ ç”Ÿæˆå¹²æ‰°é¡¹...")
            simple_vars = [z3.Bool(var) for var in variables[:5]]  # é™åˆ¶æ•°é‡é¿å…è¿‡å¤š
            generator = DistractorGenerator(available_vars=simple_vars)
            distractors = generator.generate_all(valid_steps[:2], num_per_strategy=1)
            print(f"ç”Ÿæˆäº† {len(distractors)} ä¸ªå¹²æ‰°é¡¹")

            # 5. æ ¼å¼åŒ–è¾“å‡º
            print("\nğŸ“ æ ¼å¼åŒ–çš„è¾“å…¥ä¿¡æ¯:")
            print("Z3è¡¨è¾¾å¼ç¤ºä¾‹:")
            for i, step in enumerate(valid_steps[:2], 1):
                print(f"  Step {i}: {step.get('conclusion', 'N/A')}")

            print("\nå¹²æ‰°é¡¹ç¤ºä¾‹:")
            for i, d in enumerate(distractors[:3], 1):
                print(f"  Distractor {i}: {d.get('description', 'N/A')}")

            print("\nâœ… æ¨¡æ‹Ÿç”Ÿæˆæµç¨‹å®Œæˆ - æ‰€æœ‰ç»„ä»¶æ­£å¸¸å·¥ä½œ")
        else:
            print("âš ï¸  æ²¡æœ‰æœ‰æ•ˆçš„æ¨ç†æ­¥éª¤å¯ç”¨äºç”Ÿæˆ")

    except Exception as e:
        print(f"âŒ æ¨¡æ‹Ÿç”Ÿæˆè¿‡ç¨‹ä¸­å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()


def create_default_prompt_template(path: str):
    """åˆ›å»ºé»˜è®¤çš„promptæ¨¡æ¿"""
    default_template = """You are a symbolic z3py logic code generator and an LSAT-style question author.

Given the Z3-style logic expressions below, generate a single-choice LSAT-style reasoning question:

Z3 Rules:
{z3_exprs}

Variable Descriptions:
{var_bindings}

Reasoning Chain:
{logical_steps}

Instructions:
1. Create a realistic scenario that illustrates the reasoning chain
2. Provide four answer choices (A, B, C, D) 
3. Return only valid JSON format

Output JSON format:
{{
  "context": "...",
  "question": "...", 
  "answers": ["A. ...", "B. ...", "C. ...", "D. ..."],
  "label": "A",
  "z3": ["var1 = Bool('var1')", "Implies(var1, var2)"]
}}"""

    Path(path).parent.mkdir(parents=True, exist_ok=True)
    with open(path, 'w', encoding='utf-8') as f:
        f.write(default_template)


def test_batch_generation():
    """æµ‹è¯•æ‰¹é‡ç”Ÿæˆï¼ˆå°è§„æ¨¡ï¼‰"""
    print("\n=== ğŸš€ æµ‹è¯•æ‰¹é‡ç”Ÿæˆ ===")

    # è¿™é‡Œåªåšæ¨¡æ‹Ÿï¼Œä¸å®é™…è°ƒç”¨LLM
    print("æ‰¹é‡ç”Ÿæˆéœ€è¦å®é™…çš„LLMè°ƒç”¨ï¼Œå»ºè®®:")
    print("1. ç¡®ä¿API keyæ–‡ä»¶å­˜åœ¨ä¸”æœ‰æ•ˆ")
    print("2. è¿è¡Œ dataset_generator.py çš„ main() å‡½æ•°")
    print("3. æ ¹æ®éœ€è¦è°ƒæ•´ num_samples å‚æ•°")


if __name__ == "__main__":
    print("ğŸ”¬ æ•°æ®é›†ç”Ÿæˆæµ‹è¯•")
    print("=" * 50)

    test_single_sample()
    test_batch_generation()

    print("\n" + "=" * 50)
    print("âœ… æµ‹è¯•å®Œæˆ")
    print("\nä½¿ç”¨è¯´æ˜:")
    print("1. ç¡®ä¿ api_key/ ç›®å½•ä¸‹æœ‰æœ‰æ•ˆçš„API keyæ–‡ä»¶")
    print("2. è¿è¡Œ python dataset_generator.py å¼€å§‹æ‰¹é‡ç”Ÿæˆ")
    print("3. ç”Ÿæˆçš„æ•°æ®é›†å°†ä¿å­˜ä¸º JSONL æ ¼å¼")